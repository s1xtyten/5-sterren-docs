{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Het 5-sterren model voor transparante algoritmes","text":"<p>Welkom in de online toolkit! Ga direct naar:</p> <p>- het Whitepaper (visiedocument) - het Model (keuzehulp)</p>"},{"location":"#van-black-box-algoritmes-naar-een-5-sterren-transparantie","title":"Van black-box algoritmes naar een 5-sterren-transparantie!","text":"<p>Er is vanuit de samenleving een groeiende zorg rond de inzet en ontwikkeling van algoritmes in (besluitvormings)processen in het openbaar bestuur. Niet alleen de manier waarop de overheid besluiten neemt over burgers is voor hen ondoorzichtig; ook de algoritmische systemen die daarvoor worden ingekocht en toegepast zijn lastig te doorgronden, ook voor ambtenaren zelf. Dit heeft niet alleen negatieve impact op de informatiepositie van burgers, maar ook op die van de overheid ten opzichte van de technologie die ze zelf inzet. Daardoor groeit de druk op de overheid om meer openheid en transparantie te bieden over algoritmes, om inzicht te krijgen in hoe de algoritmes werken die nu al op grote schaal worden ingezet. Anders gezegd: transparantie is nodig om als overheid grip te krijgen op manier waarop besluitvorming tot stand komt en wat de impact daarvan op mensen is, en om als burger beter in staat te zijn om te begrijpen hoe de overheid haar taken uitvoert. </p> <p>In beleid en wetgeving wordt al veel nadruk gelegd op transparantie en openheid als principe of uitgangspunt - zoals te zien aan de vele Algoritmeregisters - maar het ontbreekt nog aan een uitvoerbare of eenduidige vertaling naar de praktijk: waarover moet precies transparantie of openheid geboden worden, op welke doelgroep zou dit gericht moeten worden en met welk eindresultaat, en hoe zouden deze maatregelen dan vorm moeten krijgen in de technische of organisatorische praktijk? Daarnaast zijn overheden vaak afhankelijk van de expertise van (commerci\u00eble) derde partijen voor het ontwikkelen van deze technologie, die uit zakelijke overwegingen niet altijd even bereid zijn om daarover transparantie en openheid te bieden. Dit leidt bij (bestuurders van) overheidsorganisaties tot handelingsverlegenheid, verwarring, aarzeling en frustratie bij het realiseren van transparantie en openheid rond algoritmes in de praktijk, met maatschappelijk wantrouwen en zelfs schending van mensenrechten als gevolg. </p> <p>Het project Transparante algoritmen: van black box naar vijf sterren richt zich op het ontwikkelen van een praktische toolkit voor bestuurders in de publieke sector, ge\u00efnspireerd op het \u201c5 Star Open Data\u201d model van Tim Berners-Lee. Om dit te realiseren onderzoeken we inzichten van experts van binnen en buiten de overheid, maar betrekken daarnaast ook diverse perspectieven uit de samenleving d.m.v. een burgerpanel. De toolkit zal bestaan uit 2 componenten: een \u2018visiedocument\u2019 dat als leidraad gebruikt kan worden voor het opstellen van organisatorische ambities rond transparantie en het cre\u00ebren van bewustzijn op bestuursniveau, en een \u2018model\u2019 om praktische handvatten te bieden voor het stapsgewijs realiseren van transparantie binnen overheidsorganisaties. </p>"},{"location":"model/","title":"Het model / de keuzehulp","text":""},{"location":"model/#verdere-toelichting-per-niveau","title":"Verdere toelichting per niveau","text":"<p>1 \u2605: \u201cGepubliceerd\u201d De eerste ster wordt behaald wanneer er \u00fcberhaupt informatie over het algoritme en de toepassing door de organisatie publiek beschikbaar is, bij voorkeur in een \u201calgoritmeregister\u201d. Dat betekent een beschrijving van de algemene kenmerken van het algoritme, waarin de volgende onderdelen minimaal worden besproken: \u00b7   Beschrijving van het doel/de functie van het algoritme; \u00b7   Beschrijving van de rol van het algoritme in relatie tot het proces waarin het gebruikt wordt; \u00b7   Een risicoclassificatie van het algoritme.</p> <p>Met deze informatie informeer je over het gebruik van het algoritme, waarom het wordt ingezet, welke risico\u2019s er zijn, wat de (indirecte) impact is en welke keuze gemaakt zijn om bijvoorbeeld risico\u2019s in te perken en waarborgen te stellen. Zodat individuen en andere stakeholders kunnen weten dat een algoritme ingezet wordt en kunnen bekijken hoe dit impact heeft. Deze informatie moet beschikbaar worden gesteld in begrijpelijke taal: B1-niveau. 2 \u2605:  \u201cUitgelegd\u201d Op dit niveau wordt beschreven wat er gedaan is/wordt om te zorgen dat het algoritme doet wat het moet doen. Er wordt hiervoor een beschrijving gegeven van hoe het algoritme is getraind, geoptimaliseerd en op bias is gecontroleerd. Denk hierbij bijvoorbeeld aan de volgende onderdelen: \u00b7   Een reflectie op normatieve keuzes en definities (bijv. de keuze voor een bepaalde eerlijkheidsdefinitie); \u00b7   Welke optimalisatiecriteria er gehanteerd worden; \u00b7   Welke beheersmaatregelen er toegepast zijn/gaan worden (bijv. testing/impact assessment); \u00b7   Wie of welke partijen verantwoordelijk zijn voor de life-cycle/toezicht/verbetering; \u00b7   Een stroomschema van de inputs en outputs gedurende het proces.</p> <p>Met deze toelichting informeer je ook over de wijze waarop de werking en de effecten van het algoritme wordt gemonitord, zodat het algoritme blijft doen wat het moet. Hiermee biedt je transparantie over de gevolgen van de toepassing van het algoritme op de langere termijn, en op welke maatregelen of afspraken later ge\u00ebvalueerd kan worden.</p> <p>3 \u2605:  \u201cGecontroleerd\u201d Op dit niveau wordt niet alleen beschreven wat er gedaan is om te zorgen dat het algoritme doet wat het moet doen, maar kan dit ook aangetoond worden. Hierbij worden resultaten gedeeld die laten zien dat het algoritme  \u201cgoed\u201d en  \u201ceerlijk\u201d werkt. Dit kan bijvoorbeeld aangetoond worden door het delen van: \u00b7   Auditresultaten; \u00b7   Monitoringsdata; \u00b7   Resultaten van ethische toetsing (bijv. van een eventuele ethische commissie, of een IAMA-traject (Impact Assessment Mensenrechten en Algoritmes); \u00b7   Hoe het algoritme getest en gevalideerd is, en wat daarvan de resultaten zijn; \u00b7   Hoe ervoor gezorgd is dat de kwaliteit van de trainingsdata voldoende is, ook vanuit ethisch perspectief; \u00b7   Andere resultaten van de \u201cchecks en balances\u201d die onderdeel vormen van de life-cycle .</p> <p>Het aantonen van een \u201cgoede\u201d  en \u201ceerlijke\u201d werking, helpt bij het opbouwen van extern vertrouwen in de werking en toepassing van een algoritme. Het geeft nader zicht op de validiteit en betrouwbaarheid van de gegeven informatie.</p> <p>4 \u2605: \u201cTestbaar\u201d Op dit niveau kunnen belanghebbenden zelf het algoritme gaan testen. Mensen kunnen dan zelf inzien welke output er geleverd wordt bij welke input. Dit kan bijvoorbeeld gerealiseerd worden middels: \u00b7   Een API waarmee resultaten opgevraagd kunnen worden; \u00b7   Een \u201cmock-up\u201d systeem (wanneer volledige openheid niet geboden kan worden uit b.v. veiligheidsoverwegingen); \u00b7   Test-data, eventueel \u201csynthetisch\u201d (niet de daadwerkelijk gevoelige data maar een vergelijkbare neutrale set)</p> <p>Hiermee wordt het algoritme en de werking tastbaar en daarmee ook testbaar. Dat is een voorwaarde om een open gesprek te kunnen voeren over waarom het algoritme tot bepaalde uitkomsten komt, hoe deze resultaten ge\u00efnterpreteerd moeten worden, of deze uitkomsten wenselijk zijn, en (dus) of de toepassing van het algoritme in een bepaald proces verantwoord en gerechtvaardigd is. </p> <p>5 \u2605: \u201cOpen\u201d Op dit niveau is het algoritme volledig open. De code, data, beheersmaatregelen en ontwerpkeuzes zijn volledig inzichtelijk, uiteraard op een manier waarbij de privacy van de ontwikkelaars en andere betrokkenen niet wordt aangetast of voor onveilige situaties kan zorgen. De 5 sterren voor maximale openheid is bedoeld om experts of toezichthoudende partijen de mogelijkheid te geven om het algoritme volledig te doorgronden. Concreet kan dit bijvoorbeeld door middel van: \u00b7   Het beschikbaar stellen van de broncode in combinatie met contextuele informatie, zoals een \u201cmodel card\u201d \u00b7   Het beschikbaar stellen van de trainingsdata \u00b7   Het volledig transparant zijn over de door de organisatie gemaakte afwegingen en effecten m.b.t. de toepassing van het algoritme</p>"},{"location":"whitepaper/","title":"Whitepaper","text":"<pre><code>Door: de 5 sterren-community\n\nVersie: 0.9 (dd. 22 mei \u201824)\n</code></pre>"},{"location":"whitepaper/#1-de-uitdaging","title":"1. De uitdaging","text":"<p>Algoritmegebruik door overheden is niet transparant, met maatschappelijke schade als gevolg</p> <p>Diagnose: Er is vanuit de samenleving een groeiende zorg rond algoritmes, en daarmee grote druk op de overheid om meer transparantie te bieden over de inzet en ontwikkeling van algoritmes. Wat precies verstaan wordt onder een \u201calgoritme\u201d is breed, complex en aan discussie onderhevig, maar bij de risico\u2019s en uitdagingen gaat het zowel om de technologie als om de manier waarop het in processen wordt ingezet. De Algemene Rekenkamer concludeert echter in het rapport Aandacht voor algoritmes (2021) dat er op dit moment onvoldoende wordt toegezien op de kwaliteit en risico\u2019s van de inzet van algoritmes door overheden. Maar om inzicht te krijgen in hoe een algoritme werkt en wat de effecten ervan zijn \u2013 om grip te krijgen op algoritmische processen \u2013 is transparantie daarover nodig. Echter opereren \u201cAI-systemen soms op een weinig transparante, of zelfs onnavolgbare wijze\u201d. </p> <p>Dat geldt in het bijzonder voor de publieke sector, waar algoritmes in toenemende mate worden toegepast om in te grijpen in de maatschappij en in mensenlevens. Bovendien zijn overheden vaak afhankelijk van de expertise van (commerci\u00eble) derde partijen voor het ontwikkelen van deze technologie, die uit zakelijke overwegingen niet altijd even bereid zijn om daarover transparantie en openheid te bieden. </p> <p>Tenslotte wordt er in beleid en wetgeving veel gehamerd op transparantie en openheid als principe of uitgangspunt, maar ontbreekt het vervolgens aan een uitvoerbare of eenduidige vertaling naar de praktijk: waarover moet precies transparantie of openheid geboden worden, op welke doelgroep zou dit gericht moeten worden en met welk eindresultaat, en hoe zouden deze maatregelen dan vorm moeten krijgen in de technische of organisatorische praktijk?  </p> <p>Effect: Ondanks dat het belang van transparantie over de inzet van algoritmes duidelijk is, leidt de hierboven beschreven situatie binnen overheidsorganisaties \u2013 zowel bij bestuurders en management als in de uitvoering \u2013 tot handelingsverlegenheid, verwarring, aarzeling en frustratie bij het realiseren van transparantie en openheid rond algoritmes in de praktijk. Dat vormt een barri\u00e8re voor de verantwoorde inzet van algoritmes door overheden, wat leidt tot maatschappelijk wantrouwen en zelfs schending van mensenrechten. </p>"},{"location":"whitepaper/#2-context","title":"2. Context","text":"<p>Het belang van transparantie, en waarom de uitvoering ervan lastig is</p> <p>Transparantie \u2013 in de context van algoritmes \u2013 is als principe of vereiste sterk verankerd in wetgeving, beleid, richtlijnen en kaders. Deze documenten wekken de suggestie dat transparantie een soort moreel of maatschappelijk eindpunt is.  Maar het is cruciaal om transparantie niet als einddoel te zien, maar als een middel om een hoger doel te bereiken: inzicht bieden in de manier waarop overheidsorganisaties hun taken (met behulp van algoritmes) uitvoeren, daar als overheid verantwoording over af te kunnen leggen, en het mogelijk maken van publiek toezicht op de kwaliteit en rechtvaardigheid waarmee de overheid haar taken uitvoert. Transparantie is daarmee een essenti\u00eble voorwaarde voor het verantwoord inzetten van algoritmes. </p> <p>Omdat transparantie op dit moment nog te veel als abstract einddoel wordt gezien, is het uitvoeren daarvan in de praktijk zeer lastig. Want zonder een hoger doel waarvoor transparantie belangrijk is kunnen bepaalde vragen niet worden beantwoord, zoals voor wie (doelgroepen) transparantie belangrijk is, over welke zaken transparantie nodig is, en hoeveel transparantie in verschillende situaties gepast of genoeg is. Dat maakt dat er op dit moment een kloof bestaat tussen beleid en uitvoering, waardoor - ondanks de druk van bovenaf - het uitvoeren van transparantie in de praktijk erg lastig is. </p> <p>Deze situatie leidt tot een aantal ongewenste en schadelijke effecten:  \u00b7   Handelingsverlegenheid, aarzeling en frustratie bij het naar de praktijk vertalen van wetgeving en beleid rond transparantie \u00b7   Verwarring en onduidelijkheid over rollen en verantwoordelijkheden  \u00b7   Een cultuur binnen overheidsorganisaties waarin risicovermijding de boventoon voert, en er te veel wordt gekeken naar technische maatregelen voor menselijke uitdagingen</p> <p>Hieronder lichten we deze effecten verder toe. </p> <p>Er is sprake van handelingsverlegenheid, aarzeling en frustratie bij het naar de praktijk vertalen van wetgeving en beleid rond transparantie Het is op dit moment om verschillende redenen voor overheden lastig om transparantie in de praktijk te realiseren, en dat heeft een aantal oorzaken. Ten eerste is er grote onduidelijkheid over wat transparantie als begrip betekent. De uitwerking van transparantie op beleidsniveau is vooral theoretisch en abstract, en biedt geen eenduidige, heldere blik op wat transparantie betekent binnen de context van algoritmes, laat staan binnen verschillende toepassingsgebieden.Ten tweede is er sprake van een kloof tussen beleid en uitvoering. Er is grote onduidelijkheid over hoe wetgeving en beleid concreet vorm moeten krijgen in de uitvoeringspraktijk (de algoritmische systemen zelf en de processen waarin ze worden toegepast). Dit is een bekende, lastig uitdaging met name voor overheden, en is niet beperkt tot transparantie in de context van algoritmes. In de context van algoritmes is dat in het bijzonder schrijnend, omdat transparantie zo\u2019n essenti\u00eble voorwaarde is om schade aan burgers en de samenleving te voorkomen. </p> <p>Er is verwarring en onduidelijkheid over rollen, verantwoordelijkheden en werkwijzen</p> <p>Er bestaat daarnaast ook veel onduidelijkheid over de belegging van rollen en verantwoordelijkheden binnen de organisatie die worden opgezadeld met de taak om transparantie uit te voeren. Mensen willen graag het goede doen, en dat geldt zeker ook voor professionals van de overheid die uiteindelijk werken aan een betere samenleving, voor de publieke waarden. Maar het is op dit moment totaal niet duidelijk wie verantwoordelijk is voor welke taken, of welke werkwijze er dient te worden gehanteerd, wat de uitvoering ervan sterk in de weg zit. </p> <p>Er heerst een cultuur binnen overheidsorganisaties waarin risicovermijding de boventoon voert, en er te veel wordt gekeken naar technische maatregelen voor menselijke uitdagingen</p> <p>Er is binnen de overheid sprake van een heersende cultuur die niet bevorderlijk is voor transparantie en openheid. Dat kan in het algemeen al geconcludeerd worden uit de \u201ctoeslagenaffaire\u201d bij de Belastingdienst en andere voorbeelden van overheidsorganisaties die de afgelopen tijd negatief in het nieuws zijn gekomen vanwege de toepassing van schadelijke risico- of fraude-voorspellende systemen,). We zien het ook in ons werk met of bij de overheid: er wordt sterk gestuurd op risicovermijding vanuit het perspectief van de overheid zelf, in plaats van vanuit het perspectief van de samenleving. In de praktijk leidt dat ertoe dat er wordt gestuurd op het drukken van kosten, het maximaliseren van effici\u00ebntie, en het voorkomen van negatieve publiciteit en aandacht. </p> <p>Niet alleen staat dat haaks op transparant en open zijn; het cre\u00ebert ook een cultuur waarin er sterk wordt gestuurd op meetbare, kwantificeerbare resultaten. Het resultaat daarvan is dat er bij de aanpak van uitdagingen of risico\u2019s een overmatige focus ligt op de techniek, terwijl goede oplossingen voor maatschappelijke uitdagingen vaak liggen in een meer systematische, organisatorische, participatieve, sociale of menselijke aanpak die zich niet altijd eenvoudig laat kwantificeren. </p> <p>Vanuit het heersende mantra van de digitalisering, het datagedreven werken en de huidige hype rond algoritmes, heerst er binnen de overheid een zogeheten \u201ctechnology push\u201d: er moet ge\u00efnnoveerd worden om niet de boot te missen, technologische kansen moeten worden gepakt, maar daarmee wordt voorbij gegaan aan de vraag of technologie \u00fcberhaupt de beste oplossing is voor een bepaald probleem, hoe die technologie het beste kan worden ge\u00efmplementeerd in de huidige bestaande processen, en of de (in)directe gevolgen voor de samenleving de keuze voor de technologie kunnen rechtvaardigen. </p> <p>Let op: de oorzaak van deze cultuur ligt niet alleen bij overheidsorganisaties en hun medewerkers. Ook de politiek heeft hier een groot aandeel in, met lastige top-down prikkels waar ambtenaren gehoor aan dienen te geven. Bovendien heerst binnen de media een cultuur van \u201csensatie\u201d, controverse en negativiteit op dit onderwerp, wat de drempel voor overheden om transparanter te zijn nog hoger maakt. En dat terwijl tegelijkertijd vanuit het Ministerie van Binnenlandse Zaken en toezichthouders (AP, Agentschap Telecom) steeds meer wordt gehamerd en gestuurd op verplicht publiceren van algoritmes, uitvoeren van impact assessments en audits (ook op transparantie), en het centraal stellen van de burger. </p> <p>Door deze combinatie van factoren maken vooral commerci\u00eble maar ook publieke organisaties zich schuldig aan \u201ctransparency washing\u201d: de suggestie wekken dat je transparant bent, maar daarbij bewust een keuze maken voor zaken die vanuit het perspectief van risicovermijding \u201cveilig\u201d is, en eigenlijk niet bijdragen aan het uiteindelijke doel van transparantie dat we eerder beschreven. </p>"},{"location":"whitepaper/#3-onze-oplossing","title":"3. Onze oplossing","text":"<p>Een raamwerk voor stapsgewijs realiseren van transparante algoritmes: Het \u201c5 sterren-model\u201d Transparantie is dus een kernvoorwaarde voor verantwoorde inzet van algoritmes door overheden, maar daar wordt op dit moment nog niet (genoeg) aan voldaan. Aangespoord door grote ambities op het gebied van digitalisering groeit tegelijkertijd het aantal algoritmes dat door overheidsorganisaties wordt toegepast in rap tempo. Om die reden is de urgentie om de ongewenste en schadelijke effecten van het gebrek aan transparantie aan te pakken hoog. De oplossing ligt in het bieden van duidelijkheid en uitvoerbaarheid aan degenen die verantwoordelijk zijn voor het in de praktijk brengen van transparantie. Als oplossing introduceren wij daarom een stapsgewijs raamwerk voor transparantie: het 5 sterren-model.</p> <p>NB: Deze visuele weergave van het model wordt in meer detail beschreven in het volgende hoofdstuk.</p> <p>Het 5 sterren-model is een hulpmiddel dat overheidsorganisaties ondersteuning kan bieden met:</p> <p>\u00b7   Helderheid bieden over transparantie-eisen, op een manier die gevoelig is voor de context van de toepassing. \u00b7   Praktische uitvoerbaarheid: waar sta je als organisatie, waar begin je met het bieden van transparantie, waar ligt de prioriteit? \u00b7   Organisaties en medewerkers in staat stellen om hun ambitie en doelen op het gebied van transparantie uit te drukken en te communiceren \u00b7   Organisaties en medewerkers in staat stellen om verantwoording af te leggen over gemaakte keuzes op het gebied van transparantie \u00b7   Het (publiek) betwistbaar maken van algoritmische systemen of processen waarin algoritmes worden gebruikt \u00b7   Verschillende groepen belanghebbenden bedienen op basis van de specifieke behoeftes per doelgroep (i.e. burgers, ontwikkelaars, ambtenaren) \u00b7   (Culturele) transitie teweegbrengen: transparantie moet \u201cbusiness as usual\u201d zijn, en eventuele uitzonderingen verdienen zorgvuldige uitleg</p> <p>Beheerd door een open community, en met Open State Foundation als hoeder</p> <p>Het 5 sterren-model is een lopend project dat wordt ontwikkeld en beheerd door een open gemeenschap van een zo divers mogelijke groep mensen. Wat ons betreft is iedereen belanghebbende, of men zich daar bewust van is of niet. Iedereen die interesse heeft kan dus meewerken en wordt ook van harte uitgenodigd dat te doen. Dat kunnen organisatieteams of individuele experts zijn, maar vooral iedereen die om wat voor reden dan ook ge\u00efnteresseerd, betrokken of bezorgd is (want een belang hebben we allemaal). </p> <p>Open State Foundation neemt als betrokken en ervaren maatschappelijke organisatie op het gebied van transparantie en openheid bij de overheid de rol van ambassadeur of hoeder van het model op zich. Dat betekent dat zij hun expertise en netwerk zullen inzetten voor de verspreiding en de activatie ervan.</p> <p>Voor de gehele publieke sector (en het liefst ook de rest van de organisaties)</p> <p>Het 5 sterren-model is bedoeld voor alle organisaties, in het bijzonder publieke organisaties, die met algoritmes werken en openheid willen of moeten geven. Om toch wat richting te geven aan de impact van het model richt het zich in het bijzonder op twee groepen: \u00b7   Bestuurders en leidinggevenden, als instrument om intern het gesprek te voeren over visie en ambitie, om bewustzijn te cre\u00ebren, en om strategie of governance mee te articuleren en vorm te geven \u00b7   Op innovatieprofessionals, als praktische handvatten om in projecten en innovatietrajecten transparantie om te kunnen zetten in concrete, uitvoerbare maatregelen </p> <p>NB: Het model is gericht op organisatieprocessen en toepassingscontext (i.e. ontwikkeling \u2013 inkoop \u2013 beheer \u2013 verantwoording), niet alleen op de specifieke technologie die wordt ingezet. </p>"},{"location":"whitepaper/#4-het-5-sterren-model-verdere-specificatie-en-uitwerking","title":"4. Het 5 sterren-model: verdere specificatie en uitwerking","text":"<p>Algemeen uitgangspunt Het 5 sterren-model een instrument dat gericht is op 1) het helpen van bestuurders en leidinggevenden bij het articuleren van hun ambities omtrent transparante algoritmes, en 2) het bieden van duidelijkheid over hoe transparantie in de praktijk verwezenlijkt kan worden. Er is geen  \u201ctoezichthouder\u201d of certificerende partij die de sterren \u201cuitreikt\u201d; organisaties kunnen het model vrij gebruiken. Vrij gebruik betekent hier nadrukkelijk niet \u201cvrijblijvend\u201d: een toezegging of belofte om een bepaald ambitieniveau te verwezenlijken kan door (domein)toezichthouders en volksvertegenwoordigers w\u00e9l gebruikt worden als toetsingsbasis. Het geeft ons als samenleving en als mensen ook de mogelijkheid om overheden te bevragen over het niet voldoen aan een bepaald niveau van transparantie, of andersom uiteraard: overheidsorganisaties kunnen ook vertrouwen en waardering winnen door w\u00e9l aan bepaald niveau te voldoen. </p> <p>Wat er onder elke ster of niveau valt is zoals eerder gesteld continu in ontwikkeling om ruimte te maken voor voortschrijdend inzicht en nieuwe perspectieven; iets dat in deze razendsnel veranderende sector onmisbaar is. Hieronder geven we aan wat op dit moment per ster/niveau geldt:</p> <p>1 \u2605: \u201cGepubliceerd\u201d De eerste ster wordt behaald wanneer er \u00fcberhaupt informatie over het algoritme en de toepassing door de organisatie publiek beschikbaar is, bij voorkeur in een \u201calgoritmeregister\u201d. Dat betekent een beschrijving van de algemene kenmerken van het algoritme, waarin de volgende onderdelen minimaal worden besproken: \u00b7   Beschrijving van het doel/de functie van het algoritme; \u00b7   Beschrijving van de rol van het algoritme in relatie tot het proces waarin het gebruikt wordt; \u00b7   Een risicoclassificatie van het algoritme.</p> <p>Met deze informatie informeer je over het gebruik van het algoritme, waarom het wordt ingezet, welke risico\u2019s er zijn, wat de (indirecte) impact is en welke keuze gemaakt zijn om bijvoorbeeld risico\u2019s in te perken en waarborgen te stellen. Zodat individuen en andere stakeholders kunnen weten dat een algoritme ingezet wordt en kunnen bekijken hoe dit impact heeft. Deze informatie moet beschikbaar worden gesteld in begrijpelijke taal: B1-niveau. 2 \u2605:  \u201cUitgelegd\u201d Op dit niveau wordt beschreven wat er gedaan is/wordt om te zorgen dat het algoritme doet wat het moet doen. Er wordt hiervoor een beschrijving gegeven van hoe het algoritme is getraind, geoptimaliseerd en op bias is gecontroleerd. Denk hierbij bijvoorbeeld aan de volgende onderdelen: \u00b7   Een reflectie op normatieve keuzes en definities (bijv. de keuze voor een bepaalde eerlijkheidsdefinitie); \u00b7   Welke optimalisatiecriteria er gehanteerd worden; \u00b7   Welke beheersmaatregelen er toegepast zijn/gaan worden (bijv. testing/impact assessment); \u00b7   Wie of welke partijen verantwoordelijk zijn voor de life-cycle/toezicht/verbetering; \u00b7   Een stroomschema van de inputs en outputs gedurende het proces.</p> <p>Met deze toelichting informeer je ook over de wijze waarop de werking en de effecten van het algoritme wordt gemonitord, zodat het algoritme blijft doen wat het moet. Hiermee biedt je transparantie over de gevolgen van de toepassing van het algoritme op de langere termijn, en op welke maatregelen of afspraken later ge\u00ebvalueerd kan worden.</p> <p>3 \u2605:  \u201cGecontroleerd\u201d Op dit niveau wordt niet alleen beschreven wat er gedaan is om te zorgen dat het algoritme doet wat het moet doen, maar kan dit ook aangetoond worden. Hierbij worden resultaten gedeeld die laten zien dat het algoritme  \u201cgoed\u201d en  \u201ceerlijk\u201d werkt. Dit kan bijvoorbeeld aangetoond worden door het delen van: \u00b7   Auditresultaten; \u00b7   Monitoringsdata; \u00b7   Resultaten van ethische toetsing (bijv. van een eventuele ethische commissie, of een IAMA-traject (Impact Assessment Mensenrechten en Algoritmes); \u00b7   Hoe het algoritme getest en gevalideerd is, en wat daarvan de resultaten zijn; \u00b7   Hoe ervoor gezorgd is dat de kwaliteit van de trainingsdata voldoende is, ook vanuit ethisch perspectief; \u00b7   Andere resultaten van de \u201cchecks en balances\u201d die onderdeel vormen van de life-cycle .</p> <p>Het aantonen van een \u201cgoede\u201d  en \u201ceerlijke\u201d werking, helpt bij het opbouwen van extern vertrouwen in de werking en toepassing van een algoritme. Het geeft nader zicht op de validiteit en betrouwbaarheid van de gegeven informatie.</p> <p>4 \u2605: \u201cTestbaar\u201d Op dit niveau kunnen belanghebbenden zelf het algoritme gaan testen. Mensen kunnen dan zelf inzien welke output er geleverd wordt bij welke input. Dit kan bijvoorbeeld gerealiseerd worden middels: \u00b7   Een API waarmee resultaten opgevraagd kunnen worden; \u00b7   Een \u201cmock-up\u201d systeem (wanneer volledige openheid niet geboden kan worden uit b.v. veiligheidsoverwegingen); \u00b7   Test-data, eventueel \u201csynthetisch\u201d (niet de daadwerkelijk gevoelige data maar een vergelijkbare neutrale set)</p> <p>Hiermee wordt het algoritme en de werking tastbaar en daarmee ook testbaar. Dat is een voorwaarde om een open gesprek te kunnen voeren over waarom het algoritme tot bepaalde uitkomsten komt, hoe deze resultaten ge\u00efnterpreteerd moeten worden, of deze uitkomsten wenselijk zijn, en (dus) of de toepassing van het algoritme in een bepaald proces verantwoord en gerechtvaardigd is. </p> <p>5 \u2605: \u201cOpen\u201d Op dit niveau is het algoritme volledig open. De code, data, beheersmaatregelen en ontwerpkeuzes zijn volledig inzichtelijk, uiteraard op een manier waarbij de privacy van de ontwikkelaars en andere betrokkenen niet wordt aangetast of voor onveilige situaties kan zorgen. De 5 sterren voor maximale openheid is bedoeld om experts of toezichthoudende partijen de mogelijkheid te geven om het algoritme volledig te doorgronden. Concreet kan dit bijvoorbeeld door middel van: \u00b7   Het beschikbaar stellen van de broncode in combinatie met contextuele informatie, zoals een \u201cmodel card\u201d \u00b7   Het beschikbaar stellen van de trainingsdata \u00b7   Het volledig transparant zijn over de door de organisatie gemaakte afwegingen en effecten m.b.t. de toepassing van het algoritme</p>"},{"location":"whitepaper/#belangrijke-overwegingen-bij-toepassing-van-het-model","title":"Belangrijke overwegingen bij (toepassing van) het model","text":"<p>Er zullen bij het lezen van dit whitepaper mensen zijn die denken: zo\u2019n ambitie is leuk, maar niet helemaal eerlijk, want niet elk algoritme k\u00e1n vijf sterren halen. Dat is een terecht punt, wanneer bijvoorbeeld  privacy (denk aan persoonsgegevens in trainingsdata) of nationale veiligheid (het risico dat criminelen hun voordeel doen met gepubliceerde informatie over beveiligingssystemen) volledige openheid onmogelijk maken. Het hoogst haalbare ambitieniveau dient dus altijd in context bekeken te worden, en wanneer geen volledig transparantie geboden kan worden, dan moeten organisaties daar niet zonder meer direct op afgerekend te worden. Mits daar een gegronde afweging tegenover staat. En over de afwegingen die aan deze besluiten ten grondslag liggen kan transparantie geboden worden. </p> <p>Ook is het belangrijk dat het 5 sterren-model niet als een checklist of een uitputtend overzicht wordt gezien, maar als een richtinggevend hulpmiddel voor ambitieniveaus. We pogen niet uitputtend te zijn, maar willen ambitieniveaus schetsen. Het kan per organisatie verschillen wat er nodig is om een sterrenniveau te behalen, omdat het afhangt van de instrumenten die gebruikt worden, en de volwassenheid op het gebied van bijvoorbeeld ethiek en data governance. We raden je daarom aan om voor je organisatie een vertaling te maken van waar je staat, wat er aan werkzaamheden nodig is om op een bepaald ambitieniveau te komen, en waar de prioriteit ligt. Daarbij kan het 5 sterren-model helpen als leidraad om intern het gesprek te voeren, en het proces vorm te geven.</p> <p>Tot slot: publieke organisaties moeten stappen zetten op het gebied van transparante algoritmes, en dat vereist tijd, ruimte en middelen. Het 5 sterren-model helpt om te concretiseren welke stappen er gezet zouden kunnen of moeten worden, maar zonder het vrijmaken van die tijd en ruimte binnen de organisatie en het bieden van handelingsruimte aan medewerkers om hiermee aan de slag te gaan zal de uitvoering spaak lopen. Dat is niet alleen vanuit moreel oogpunt problematisch; door een gebrek aan transparantie komen risico\u2019s en problemen bij de toepassing van algoritmes pas veel later aan het licht, wanneer de schade ervan groter is en het rechtzetten ervan kostbaarder. We raden daarom aan \u2013 naast de noodzaak om bestaande systemen transparanter te maken \u2013 om in ieder geval voor nieuwe projecten openheid als randvoorwaarde (\u201cdefinition-of-done\u201d) mee te nemen. </p>"},{"location":"whitepaper/#6-tips-om-met-het-model-aan-de-slag-te-gaan","title":"6. Tips om met het model aan de slag te gaan","text":"<p>Het 5 sterren-model is als instrument gericht op het articuleren van organisatorische ambities, om te helpen het gesprek te voeren en urgentie en bewustzijn te cre\u00ebren. Dit zou ook het startpunt moeten zijn voor de toepassing van het model binnen de organisatie. Maar het voorziet daarnaast ook in het bieden van handvatten om deze ambities uitvoerbaar te maken, om tastbare resultaten in de praktijk mee te realiseren. De volgende stappen kunnen helpen om met het model aan de slag te gaan: 1.  Maak op bestuurlijk niveau afspraken over een ambitieniveau dat je voor de organisatie beoogt te bereiken; 2.  Beschrijf helder wat transparantie voor jouw organisatie betekent, met aandacht voor de specifieke praktische context waar jouw organisatie mee te maken heeft, en de kernwaarden van je organisatie; 3.  Beleg de verantwoordelijkheden is voor de realisatie van 1 en 2 duidelijk binnen je organisatie, en maak daarvoor ruimte en middelen vrij; 4.  Inventariseer welke algoritmes er binnen je organisatie worden gebruikt, en waarvoor; 5.  Verzamel minimale informatie over het algoritme; 6.  Bepaal het risiconiveau en de impact (zoals ook vanuit de AI Act een verplichting wordt); 7.  Registreer en publiceer volgens de organisatierichtlijnen (stap 2); 8.  Transparantie begint al aan de voorkant, want zonder de juiste inkoopvoorwaarden wordt het bieden van transparantie op een later moment lastig. Neem dit dus al mee bij het inkopen van de technologie. </p>"},{"location":"whitepaper/#7-conclusie-en-call-to-arms","title":"7. Conclusie en call to arms!","text":"<p>Dit raamwerk helpt organisaties in kaart te brengen waar ze staan en waar ze moeten beginnen, waar nog werk nodig is, en in welke volgorde, zodat tijd en middelen goed besteed worden. Verlaag de drempel, vergroot het handelingsvermogen, verhoog het bewustzijn, en wees open. Door het van de gemeenschap te maken borg je deskundigheid maar ook diversiteit en inclusie. We roepen iedereen daarom op om mee te helpen bij de volgende essenti\u00eble taken:</p> <p>\u00b7   Doe (denk, bouw en praat) mee! \u00b7   Spread the word: ambassadeurs op alle lagen \u2013 in de board rooms, binnen de universiteiten, op de redacties van media, bij de kopieerapparaten, in de kroeg \u2013 zijn nodig om een beweging op gang te brengen; \u00b7   Pilot cases om model op te \u201ctesten\u201d: Organisaties die bereid zijn? Systemen die kansrijk zijn?  \u00b7   Nay-sayers, say your say! We roepen kritische blikken en gesignaleerde beren op de weg actief op om ons te overtuigen van hoe het w\u00e9l zou moeten; \u00b7   ...</p> <p>Achtergrond/literatuur</p> <p>Morley, J., Floridi, L., Kinsey, L. et al. From What to How: An Initial Review of Publicly Available AI Ethics Tools, Methods and Research to Translate Principles into Practices. Sci Eng Ethics 26, 2141\u20132168 (2020). https://doi.org/10.1007/s11948-019-00165-5</p> <p>Upol Ehsan, Q. Vera Liao, Michael Muller, Mark O. Riedl, and Justin D. Weisz. 2021. Expanding Explainability: Towards Social Transparency in AI systems. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI '21). Association for Computing Machinery, New York, NY, USA, Article 82, 1\u201319. https://doi.org/10.1145/3411764.3445188</p> <p>Alfrink, K., Keller, I., Kortuem, G. et al. Contestable AI by Design: Towards a Framework. Minds &amp; Machines (2022). https://doi.org/10.1007/s11023-022-09611-z</p> <p>Zalnieriute, Monika, \u201cTransparency-Washing\u201d in the Digital Age: A Corporate Agenda of Procedural Fetishism (2021). Critical Analysis of Law, 8(1) 2021, pp. 39-53, UNSW Law Research Paper No. 21-33, Available at SSRN: https://ssrn.com/abstract=3805492</p> <p>Prem, E. From ethical AI frameworks to tools: a review of approaches. AI Ethics 3, 699\u2013716 (2023).</p> <p>K. Haresamudram, S. Larsson and F. Heintz, \"Three Levels of AI Transparency,\" in Computer, vol. 56, no. 2, pp. 93-100, Feb. 2023, doi: 10.1109/MC.2022.3213181</p> <p>Eschenbach, W.J. von. Transparency and the Black Box Problem: Why We Do Not Trust AI. Philos. Technol. 34, 1607\u20131622 (2021). https://doi.org/10.1007/s13347-021-00477-0</p>"},{"location":"whitepaper/#why","title":"Why","text":""},{"location":"whitepaper/#what","title":"What","text":""},{"location":"whitepaper/#how","title":"How","text":""}]}